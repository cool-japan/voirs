[package]
name = "voirs-acoustic"
version.workspace = true
edition.workspace = true
authors.workspace = true
license.workspace = true
repository.workspace = true
homepage.workspace = true
documentation = "https://docs.rs/voirs-acoustic"
keywords = ["voirs", "acoustic", "tts", "mel-spectrogram", "vits"]
categories = ["multimedia::audio", "science", "algorithms"]
rust-version.workspace = true
description = "Acoustic model inference for VoiRS speech synthesis (VITS/FastSpeech2)"

[lib]
name = "voirs_acoustic"
crate-type = ["lib"]

[dependencies]
# ML/Tensor libraries
candle-core = { workspace = true, optional = true }
candle-nn = { workspace = true, optional = true }
candle-transformers = { workspace = true, optional = true }
ort = { workspace = true, optional = true }
safetensors.workspace = true
hf-hub = { workspace = true, features = ["tokio"] }
reqwest.workspace = true
half.workspace = true
bytemuck.workspace = true

# SciRS2 - Optimized DSP and linear algebra
scirs2-core.workspace = true
scirs2-fft.workspace = true

# NumRS2 - For loading numpy .npz voice files
numrs2.workspace = true

# Serialization
serde.workspace = true
serde_json.workspace = true
bincode.workspace = true
toml.workspace = true

# Time handling
chrono.workspace = true

# Text processing
regex.workspace = true

# Error handling
anyhow.workspace = true
thiserror.workspace = true

# Logging
tracing.workspace = true

# Async support
async-trait.workspace = true
tokio.workspace = true
futures.workspace = true

# Random number generation
fastrand.workspace = true

# System info
num_cpus.workspace = true

# Memory-mapped files for lazy loading
memmap2.workspace = true

# Logging for memory pressure handler
log.workspace = true

# VoiRS crates
voirs-g2p.workspace = true

[dev-dependencies]
voirs-vocoder.workspace = true
tracing-subscriber.workspace = true
criterion = { workspace = true }
tokio-test.workspace = true

[[bench]]
name = "simple_benchmarks"
harness = false

[features]
default = ["candle"]
candle = ["dep:candle-core", "dep:candle-nn", "dep:candle-transformers"]
onnx = ["dep:ort"]
gpu = ["metal"]  # On macOS, use Metal; on Linux/Windows would use cuda
cuda = ["candle-core?/cuda", "ort?/cuda"]
metal = ["candle-core?/metal"]
coreml = ["ort?/coreml"]
[lints]
workspace = true
