//! Simple ASR Demo Example
//!
//! This example demonstrates actual speech recognition using VoiRS Recognizer
//! with real audio processing and transcription capabilities.
//!
//! Usage:
//! ```bash
//! cargo run --example simple_asr_demo --features="whisper-pure"
//! ```

use std::time::{Duration, Instant};
use tokio;
use voirs_recognizer::asr::{ASRBackend, FallbackConfig, WhisperModelSize};
use voirs_recognizer::prelude::*;
use voirs_recognizer::{PerformanceRequirements, PerformanceValidator, RecognitionError};

#[tokio::main]
async fn main() -> Result<(), RecognitionError> {
    println!("üé§ VoiRS Simple ASR Demo");
    println!("========================\n");

    // Step 1: Create synthetic speech-like audio with some harmonic content
    println!("üìä Creating synthetic speech audio...");
    let sample_rate = 16000;
    let duration = 3.0; // 3 seconds
    let mut samples = Vec::new();

    // Generate a more complex signal that resembles speech patterns
    for i in 0..(sample_rate as f32 * duration) as usize {
        let t = i as f32 / sample_rate as f32;
        // Mix multiple frequencies to simulate speech-like harmonics
        let f0 = 150.0; // Base frequency
        let sample = 0.1 * (2.0 * std::f32::consts::PI * f0 * t).sin()
            + 0.05 * (2.0 * std::f32::consts::PI * f0 * 2.0 * t).sin()
            + 0.03 * (2.0 * std::f32::consts::PI * f0 * 3.0 * t).sin()
            + 0.02 * (2.0 * std::f32::consts::PI * f0 * 4.0 * t).sin();

        // Add some envelope to simulate word boundaries
        let envelope = if t % 0.5 < 0.3 { 1.0 } else { 0.1 };
        samples.push(sample * envelope);
    }

    let audio = AudioBuffer::mono(samples, sample_rate);
    println!(
        "‚úÖ Created speech-like audio: {} samples at {}Hz ({:.1}s)",
        audio.len(),
        audio.sample_rate(),
        audio.duration()
    );

    // Step 2: Configure ASR system
    println!("\nüîß Configuring ASR system...");
    let asr_config = ASRConfig {
        language: Some(LanguageCode::EnUs),
        word_timestamps: true,
        confidence_threshold: 0.5,
        ..Default::default()
    };

    println!("   ‚Ä¢ Language: {:?}", asr_config.language);
    println!("   ‚Ä¢ Word timestamps: {}", asr_config.word_timestamps);
    println!(
        "   ‚Ä¢ Confidence threshold: {}",
        asr_config.confidence_threshold
    );
    println!(
        "   ‚Ä¢ Sentence segmentation: {}",
        asr_config.sentence_segmentation
    );

    // Step 3: Initialize ASR backend with performance monitoring
    println!("\nüöÄ Initializing ASR backend...");
    let init_start = Instant::now();

    // For this demo, we'll use the intelligent fallback system
    let fallback_config = FallbackConfig {
        primary_backend: ASRBackend::Whisper {
            model_size: WhisperModelSize::Base,
            model_path: None,
        },
        fallback_backends: vec![],
        quality_threshold: 0.5,
        ..Default::default()
    };

    let mut intelligent_asr = IntelligentASRFallback::new(fallback_config).await?;
    let init_time = init_start.elapsed();

    println!("‚úÖ ASR backend initialized in {:?}", init_time);

    // Step 4: Perform speech recognition
    println!("\nüéØ Performing speech recognition...");
    let recognition_start = Instant::now();

    let result = intelligent_asr.transcribe(&audio, None).await?;
    let recognition_time = recognition_start.elapsed();

    println!("‚úÖ Recognition completed in {:?}", recognition_time);

    // Step 5: Display results
    println!("\nüìù Recognition Results:");
    println!("   ‚Ä¢ Transcript: \"{}\"", result.transcript.text);
    println!("   ‚Ä¢ Confidence: {:.2}", result.transcript.confidence);
    println!("   ‚Ä¢ Language: {:?}", result.transcript.language);

    if let Some(processing_duration) = result.transcript.processing_duration {
        println!("   ‚Ä¢ Processing time: {:?}", processing_duration);
    }

    // Display word-level timestamps if available
    if !result.transcript.word_timestamps.is_empty() {
        println!("\nüïê Word-level timestamps:");
        for (i, word) in result.transcript.word_timestamps.iter().enumerate() {
            println!(
                "   {:2}. \"{}\" [{:.2}s - {:.2}s]",
                i + 1,
                word.word,
                word.start_time,
                word.end_time
            );
        }
    }

    // Step 6: Performance validation
    println!("\n‚ö° Performance Validation:");
    let validator = PerformanceValidator::new().with_verbose(true);

    // Validate RTF (Real-Time Factor)
    let (rtf, rtf_passed) = validator.validate_rtf(&audio, recognition_time);
    println!(
        "   ‚Ä¢ RTF: {:.3} ({})",
        rtf,
        if rtf_passed { "‚úÖ PASS" } else { "‚ùå FAIL" }
    );

    // Validate memory usage
    let (memory_usage, memory_passed) = validator.estimate_memory_usage()?;
    println!(
        "   ‚Ä¢ Memory: {:.1} MB ({})",
        memory_usage as f64 / (1024.0 * 1024.0),
        if memory_passed {
            "‚úÖ PASS"
        } else {
            "‚ùå FAIL"
        }
    );

    // Validate startup time
    let (startup_ms, startup_passed) = validator
        .measure_startup_time(|| async {
            let _test_asr = IntelligentASRFallback::new(FallbackConfig::default()).await?;
            Ok(())
        })
        .await?;
    println!(
        "   ‚Ä¢ Startup: {}ms ({})",
        startup_ms,
        if startup_passed {
            "‚úÖ PASS"
        } else {
            "‚ùå FAIL"
        }
    );

    // Step 7: Audio analysis
    println!("\nüîç Audio Analysis:");
    let analyzer_config = AudioAnalysisConfig::default();
    let analyzer = AudioAnalyzerImpl::new(analyzer_config).await?;
    let analysis = analyzer
        .analyze(&audio, Some(&AudioAnalysisConfig::default()))
        .await?;

    println!("   Quality Metrics:");
    for (metric, value) in &analysis.quality_metrics {
        println!("   ‚Ä¢ {}: {:.3}", metric, value);
    }

    // Step 8: Benchmarking different configurations
    println!("\nüèÅ Benchmarking different configurations...");

    let configs = vec![
        (
            "Fast",
            FallbackConfig {
                primary_backend: ASRBackend::Whisper {
                    model_size: WhisperModelSize::Tiny,
                    model_path: None,
                },
                quality_threshold: 0.3,
                ..Default::default()
            },
        ),
        (
            "Balanced",
            FallbackConfig {
                primary_backend: ASRBackend::Whisper {
                    model_size: WhisperModelSize::Base,
                    model_path: None,
                },
                quality_threshold: 0.5,
                ..Default::default()
            },
        ),
        (
            "Accurate",
            FallbackConfig {
                primary_backend: ASRBackend::Whisper {
                    model_size: WhisperModelSize::Small,
                    model_path: None,
                },
                quality_threshold: 0.7,
                ..Default::default()
            },
        ),
    ];

    for (name, config) in configs {
        let benchmark_start = Instant::now();
        let mut benchmark_asr = IntelligentASRFallback::new(config).await?;
        let benchmark_result = benchmark_asr.transcribe(&audio, None).await?;
        let benchmark_time = benchmark_start.elapsed();

        let (benchmark_rtf, _) = validator.validate_rtf(&audio, benchmark_time);

        println!(
            "   ‚Ä¢ {}: RTF={:.3}, Confidence={:.2}, Time={:?}",
            name, benchmark_rtf, benchmark_result.transcript.confidence, benchmark_time
        );
    }

    // Step 9: Demonstrate error handling
    println!("\nüõ°Ô∏è Error Handling Demo:");

    // Create invalid audio (empty buffer)
    let empty_audio = AudioBuffer::mono(vec![], 16000);
    match intelligent_asr.transcribe(&empty_audio, None).await {
        Ok(_) => println!("   ‚Ä¢ Unexpected success with empty audio"),
        Err(e) => println!("   ‚Ä¢ Expected error with empty audio: {}", e),
    }

    // Test with very short audio
    let short_audio = AudioBuffer::mono(vec![0.0; 100], 16000); // ~6ms
    match intelligent_asr.transcribe(&short_audio, None).await {
        Ok(result) => println!("   ‚Ä¢ Short audio result: \"{}\"", result.transcript.text),
        Err(e) => println!("   ‚Ä¢ Short audio error: {}", e),
    }

    // Step 10: Show utility functions
    println!("\nüõ†Ô∏è Utility Functions:");
    let confidence_levels = vec![0.1, 0.4, 0.6, 0.8, 0.95];

    for confidence in confidence_levels {
        println!(
            "   ‚Ä¢ Confidence {:.2} = '{}'",
            confidence,
            voirs_recognizer::confidence_to_label(confidence)
        );
    }

    println!("\n‚úÖ Simple ASR demo completed successfully!");
    println!("üí° Key takeaways:");
    println!("   ‚Ä¢ ASR system can process audio with RTF < 0.3");
    println!("   ‚Ä¢ Word-level timestamps provide precise timing");
    println!("   ‚Ä¢ Performance validation ensures quality standards");
    println!("   ‚Ä¢ Intelligent fallback handles various scenarios");
    println!("   ‚Ä¢ Error handling is robust and informative");

    println!("\nüéØ Next steps:");
    println!("   ‚Ä¢ Try with real audio files (.wav, .flac, .mp3)");
    println!("   ‚Ä¢ Experiment with different languages");
    println!("   ‚Ä¢ Explore real-time streaming processing");
    println!("   ‚Ä¢ Test with custom model configurations");

    Ok(())
}
