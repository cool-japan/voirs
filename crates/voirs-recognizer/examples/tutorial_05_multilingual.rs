//! Tutorial 05: Multi-language Support
//!
//! This tutorial covers VoiRS Recognizer's multi-language capabilities,
//! including automatic language detection, language-specific models,
//! and cross-linguistic phoneme analysis.
//!
//! Learning Objectives:
//! - Understand supported languages and their characteristics
//! - Configure language-specific recognition
//! - Implement automatic language detection
//! - Handle multilingual audio streams
//! - Understand phoneme mapping across languages
//! - Optimize for specific language families
//!
//! Prerequisites: Complete Tutorials 01-04
//!
//! Usage:
//! ```bash
//! cargo run --example tutorial_05_multilingual --features="whisper-pure"
//! ```

use std::collections::HashMap;
use std::error::Error;
use std::time::{Duration, Instant};
use tokio::time::sleep;
use voirs_recognizer::asr::{ASRBackend, WhisperModelSize};
use voirs_recognizer::prelude::*;

#[tokio::main]
async fn main() -> Result<(), Box<dyn Error>> {
    println!("üéì Tutorial 05: Multi-language Support");
    println!("======================================\n");

    // Step 1: Introduction to multilingual processing
    println!("üåç Learning Goal: Master multilingual speech recognition");
    println!("   ‚Ä¢ Understand supported languages");
    println!("   ‚Ä¢ Configure language-specific recognition");
    println!("   ‚Ä¢ Implement automatic language detection");
    println!("   ‚Ä¢ Handle multilingual audio streams");
    println!("   ‚Ä¢ Understand phoneme mapping across languages\n");

    // Step 2: Language support overview
    println!("üìä Step 1: Language Support Overview");
    demonstrate_language_support();

    // Step 3: Language-specific configuration
    println!(
        "
üîß Step 2: Language-Specific Configuration"
    );
    demonstrate_language_configs().await?;

    // Step 4: Automatic language detection
    println!(
        "
üîç Step 3: Automatic Language Detection"
    );
    demonstrate_language_detection().await?;

    // Step 5: Multilingual audio processing
    println!(
        "
üé§ Step 4: Multilingual Audio Processing"
    );
    demonstrate_multilingual_processing().await?;

    // Step 6: Phoneme analysis across languages
    println!(
        "
üî§ Step 5: Cross-linguistic Phoneme Analysis"
    );
    demonstrate_phoneme_analysis().await?;

    // Step 7: Performance optimization by language
    println!(
        "
‚ö° Step 6: Language-Specific Optimization"
    );
    demonstrate_language_optimization().await?;

    // Step 8: Conclusion
    println!(
        "
üéâ Congratulations! You've completed Tutorial 05!"
    );
    println!(
        "
üìñ What you learned:"
    );
    println!("   ‚Ä¢ VoiRS supports 99+ languages with varying degrees of support");
    println!("   ‚Ä¢ Language-specific configuration improves accuracy");
    println!("   ‚Ä¢ Automatic language detection enables flexible applications");
    println!("   ‚Ä¢ Multilingual processing requires careful buffer management");
    println!("   ‚Ä¢ Phoneme analysis reveals linguistic relationships");
    println!("   ‚Ä¢ Language-specific optimization improves performance");

    println!(
        "
üöÄ Next Steps:"
    );
    println!("   ‚Ä¢ Tutorial 06: Performance optimization");
    println!("   ‚Ä¢ Tutorial 07: Integration examples");
    println!("   ‚Ä¢ Advanced: Custom model fine-tuning");

    Ok(())
}

fn demonstrate_language_support() {
    println!("   VoiRS Recognizer supports multiple languages through different models:");

    let language_support = vec![
        (
            "üåü Tier 1 (Excellent Support)",
            vec![
                ("English", "en-US", "Whisper + DeepSpeech + Wav2Vec2 + MFA"),
                ("Spanish", "es-ES", "Whisper + MFA"),
                ("French", "fr-FR", "Whisper + MFA"),
                ("German", "de-DE", "Whisper + MFA"),
            ],
        ),
        (
            "üî• Tier 2 (Great Support)",
            vec![
                ("Japanese", "ja-JP", "Whisper"),
                ("Chinese", "zh-CN", "Whisper"),
                ("Korean", "ko-KR", "Whisper"),
                ("Portuguese", "pt-BR", "Whisper"),
                ("Italian", "it-IT", "Whisper"),
                ("Russian", "ru-RU", "Whisper"),
            ],
        ),
        (
            "‚ö° Tier 3 (Good Support)",
            vec![
                ("Hindi", "hi-IN", "Whisper"),
                ("Arabic", "ar-SA", "Whisper"),
                ("Dutch", "nl-NL", "Whisper"),
                ("Polish", "pl-PL", "Whisper"),
                ("Turkish", "tr-TR", "Whisper"),
            ],
        ),
    ];

    for (tier, languages) in language_support {
        println!(
            "   
   {}:",
            tier
        );
        for (lang, code, support) in languages {
            println!("   ‚Ä¢ {} ({}): {}", lang, code, support);
        }
    }

    println!(
        "   
   üìã Model Capabilities:"
    );
    println!("   ‚Ä¢ Whisper: 99+ languages, multilingual, robust");
    println!("   ‚Ä¢ DeepSpeech: English only, fast, privacy-focused");
    println!("   ‚Ä¢ Wav2Vec2: English + some multilingual models");
    println!("   ‚Ä¢ MFA: Phoneme alignment for supported languages");
}

async fn demonstrate_language_configs() -> Result<(), Box<dyn Error>> {
    println!("   Different languages may require different configurations:");

    let language_configs = vec![
        (
            "English (US)",
            LanguageCode::EnUs,
            "General-purpose, works with all models",
            ASRConfig {
                preferred_models: vec!["whisper".to_string()],
                whisper_model_size: Some("base".to_string()),
                language: Some(LanguageCode::EnUs),
                enable_voice_activity_detection: true,
                chunk_duration_ms: 30000,
                ..Default::default()
            },
        ),
        (
            "Japanese",
            LanguageCode::JaJp,
            "Requires larger model for better accuracy",
            ASRConfig {
                preferred_models: vec!["whisper".to_string()],
                whisper_model_size: Some("small".to_string()), // Larger model for Japanese
                language: Some(LanguageCode::JaJp),
                enable_voice_activity_detection: true,
                chunk_duration_ms: 20000, // Shorter chunks for Japanese
                ..Default::default()
            },
        ),
        (
            "German",
            LanguageCode::DeDe,
            "Benefits from longer context for compound words",
            ASRConfig {
                preferred_models: vec!["whisper".to_string()],
                whisper_model_size: Some("base".to_string()),
                language: Some(LanguageCode::DeDe),
                enable_voice_activity_detection: true,
                chunk_duration_ms: 35000, // Longer chunks for German compounds
                ..Default::default()
            },
        ),
    ];

    for (lang_name, lang_code, description, config) in language_configs {
        println!(
            "   
   üåê {} Configuration:",
            lang_name
        );
        println!("   ‚Ä¢ Description: {}", description);
        println!("   ‚Ä¢ Language code: {:?}", lang_code);
        println!("   ‚Ä¢ Model size: {:?}", config.whisper_model_size);
        println!("   ‚Ä¢ Chunk duration: {}ms", config.chunk_duration_ms);
        println!(
            "   ‚Ä¢ Voice activity detection: {}",
            config.enable_voice_activity_detection
        );
        println!("   ‚Ä¢ Word timestamps: {}", config.word_timestamps);

        // Simulate recognition with this config
        let start_time = Instant::now();
        let result = simulate_language_recognition(lang_name, &config).await;
        let elapsed = start_time.elapsed();

        println!("   ‚Ä¢ Sample result: \"{}\"", result);
        println!("   ‚Ä¢ Processing time: {}ms", elapsed.as_millis());
    }

    Ok(())
}

async fn simulate_language_recognition(language: &str, _config: &ASRConfig) -> String {
    // Simulate processing time
    sleep(Duration::from_millis(150)).await;

    // Return language-appropriate sample text
    match language {
        "English (US)" => "Hello, how are you today?",
        "Japanese" => "„Åì„Çì„Å´„Å°„ÅØ„ÄÅ‰ªäÊó•„ÅØ„Å©„ÅÜ„Åß„Åô„ÅãÔºü",
        "German" => "Hallo, wie geht es Ihnen heute?",
        _ => "Hello world",
    }
    .to_string()
}

async fn demonstrate_language_detection() -> Result<(), Box<dyn Error>> {
    println!("   Automatic language detection enables flexible applications:");

    println!(
        "   
   üîç Language Detection Process:"
    );
    println!("   1. Analyze audio spectral characteristics");
    println!("   2. Run inference on multiple language models");
    println!("   3. Compare confidence scores across languages");
    println!("   4. Select best language and continue processing");

    // Simulate language detection on different audio samples
    let audio_samples = vec![
        (
            "English audio",
            vec![
                (LanguageCode::EnUs, 0.95),
                (LanguageCode::DeDe, 0.23),
                (LanguageCode::FrFr, 0.15),
                (LanguageCode::EsEs, 0.18),
            ],
        ),
        (
            "Spanish audio",
            vec![
                (LanguageCode::EsEs, 0.87),
                (LanguageCode::EnUs, 0.32),
                (LanguageCode::FrFr, 0.45),
                (LanguageCode::DeDe, 0.12),
            ],
        ),
        (
            "Mixed language audio",
            vec![
                (LanguageCode::EnUs, 0.65),
                (LanguageCode::FrFr, 0.62),
                (LanguageCode::DeDe, 0.58),
                (LanguageCode::EsEs, 0.45),
            ],
        ),
    ];

    for (sample_name, detections) in audio_samples {
        println!(
            "   
   üéµ Processing {}:",
            sample_name
        );

        // Simulate detection processing
        sleep(Duration::from_millis(200)).await;

        // Find best language
        let best_detection = detections
            .iter()
            .max_by(|a, b| a.1.partial_cmp(&b.1).unwrap());
        let confidence_threshold = 0.7;

        println!("   Detection results:");
        for (lang, confidence) in &detections {
            let status = if confidence > &confidence_threshold {
                "‚úÖ"
            } else {
                "‚ùå"
            };
            println!("   ‚Ä¢ {:?}: {:.1}% {}", lang, confidence * 100.0, status);
        }

        if let Some((best_lang, best_confidence)) = best_detection {
            if *best_confidence > confidence_threshold {
                println!(
                    "   üéØ Selected language: {:?} (confidence: {:.1}%)",
                    best_lang,
                    best_confidence * 100.0
                );
            } else {
                println!("   ‚ö†Ô∏è Low confidence detection - using fallback to English");
            }
        }
    }

    println!(
        "   
   üìä Detection Strategies:"
    );
    println!("   ‚Ä¢ Confidence threshold: Set minimum confidence for auto-detection");
    println!("   ‚Ä¢ Fallback language: Use when detection confidence is low");
    println!("   ‚Ä¢ Language hints: Bias detection toward expected languages");
    println!("   ‚Ä¢ Continuous detection: Re-evaluate language during long audio");

    Ok(())
}

async fn demonstrate_multilingual_processing() -> Result<(), Box<dyn Error>> {
    println!("   Processing multilingual audio streams requires special handling:");

    println!(
        "   
   üåç Multilingual Processing Challenges:"
    );
    println!("   ‚Ä¢ Language switching within audio");
    println!("   ‚Ä¢ Code-switching (mixing languages in sentences)");
    println!("   ‚Ä¢ Accent variations");
    println!("   ‚Ä¢ Cultural context differences");

    // Simulate multilingual audio stream
    let audio_stream = vec![
        (
            "English segment",
            LanguageCode::EnUs,
            "Hello, my name is John",
        ),
        ("Spanish segment", LanguageCode::EsEs, "Hola, me llamo Juan"),
        (
            "French segment",
            LanguageCode::FrFr,
            "Bonjour, je m'appelle Jean",
        ),
        (
            "Code-switching",
            LanguageCode::EnUs,
            "I speak English and espa√±ol",
        ),
    ];

    println!(
        "   
   üé§ Processing Multilingual Stream:"
    );

    let mut current_language = LanguageCode::EnUs;
    let mut language_switches = 0;

    for (segment_name, detected_lang, transcript) in &audio_stream {
        println!(
            "   
   Segment: {}",
            segment_name
        );

        // Simulate language detection
        sleep(Duration::from_millis(100)).await;

        if *detected_lang != current_language {
            println!(
                "   üîÑ Language switch detected: {:?} ‚Üí {:?}",
                current_language, detected_lang
            );
            current_language = *detected_lang;
            language_switches += 1;

            // Simulate model reconfiguration
            sleep(Duration::from_millis(200)).await;
            println!("   üîß Reconfigured ASR for {:?}", detected_lang);
        }

        // Simulate recognition
        sleep(Duration::from_millis(300)).await;
        println!("   üìù Transcript: \"{}\"", transcript);
        println!("   üéØ Language: {:?}", detected_lang);
    }

    println!(
        "   
   üìä Stream Processing Summary:"
    );
    println!("   ‚Ä¢ Total segments: {}", audio_stream.len());
    println!("   ‚Ä¢ Language switches: {}", language_switches);
    println!("   ‚Ä¢ Final language: {:?}", current_language);

    println!(
        "   
   üõ†Ô∏è Multilingual Best Practices:"
    );
    println!("   ‚Ä¢ Use continuous language detection");
    println!("   ‚Ä¢ Implement smooth model switching");
    println!("   ‚Ä¢ Buffer context across language boundaries");
    println!("   ‚Ä¢ Handle code-switching gracefully");
    println!("   ‚Ä¢ Maintain language-specific vocabularies");

    Ok(())
}

async fn demonstrate_phoneme_analysis() -> Result<(), Box<dyn Error>> {
    println!("   Phoneme analysis reveals linguistic relationships across languages:");

    println!(
        "   
   üî§ Phoneme Inventory Comparison:"
    );

    // Simulate phoneme inventories for different languages
    let phoneme_inventories = vec![
        (
            "English",
            vec![
                "p", "b", "t", "d", "k", "g", "f", "v", "Œ∏", "√∞", "s", "z", " É", " í", "h", "m",
                "n", "≈ã", "l", "r", "j", "w",
            ],
        ),
        (
            "Spanish",
            vec![
                "p", "b", "t", "d", "k", "g", "f", "Œ≤", "s", "x", "m", "n", "…≤", "≈ã", "l", " é",
                "r", "rr", "j", "w",
            ],
        ),
        (
            "German",
            vec![
                "p", "b", "t", "d", "k", "g", "f", "v", "s", "z", " É", " í", "x", "√ß", "h", "m",
                "n", "≈ã", "l", "r", "j", "w",
            ],
        ),
        (
            "Japanese",
            vec![
                "p", "b", "t", "d", "k", "g", "f", "s", "z", " É", " í", "h", "m", "n", "≈ã", "r",
                "j", "w",
            ],
        ),
    ];

    for (language, phonemes) in &phoneme_inventories {
        println!(
            "   
   üó£Ô∏è {} Phonemes ({} total):",
            language,
            phonemes.len()
        );
        let phoneme_str = phonemes.join(", ");
        println!("   {}", phoneme_str);
    }

    println!(
        "   
   üîç Cross-linguistic Phoneme Analysis:"
    );

    // Analyze phoneme similarities
    let sample_word = "hello";
    let phoneme_mappings = vec![
        ("English", "/h…õlo ä/"),
        ("Spanish", "/Ààe.lo/"),
        ("German", "/haÀàloÀê/"),
        ("Japanese", "/he.ro/"),
    ];

    println!(
        "   
   Word: \"{}\"",
        sample_word
    );
    for (language, phonemes) in phoneme_mappings {
        println!("   ‚Ä¢ {}: {}", language, phonemes);
    }

    println!(
        "   
   üîÑ Phoneme Mapping Applications:"
    );
    println!("   ‚Ä¢ Cross-language pronunciation models");
    println!("   ‚Ä¢ Accent adaptation systems");
    println!("   ‚Ä¢ Language learning applications");
    println!("   ‚Ä¢ Speech synthesis voice conversion");

    Ok(())
}

async fn demonstrate_language_optimization() -> Result<(), Box<dyn Error>> {
    println!("   Language-specific optimization improves performance:");

    println!(
        "   
   ‚ö° Optimization Strategies by Language Family:"
    );

    let optimization_strategies = vec![
        (
            "Germanic Languages (English, German, Dutch)",
            vec![
                "Longer context windows for compound words",
                "Stress-based syllable detection",
                "Consonant cluster handling",
                "Modal particle recognition",
            ],
        ),
        (
            "Romance Languages (Spanish, French, Italian)",
            vec![
                "Vowel-centric processing",
                "Syllable-timed rhythm detection",
                "Liaison and elision handling",
                "Gender agreement patterns",
            ],
        ),
        (
            "East Asian Languages (Japanese, Chinese, Korean)",
            vec![
                "Tone recognition and processing",
                "Character-based text processing",
                "Pitch accent detection",
                "Morphological analysis",
            ],
        ),
    ];

    for (family, strategies) in optimization_strategies {
        println!(
            "   
   üåê {}:",
            family
        );
        for strategy in strategies {
            println!("   ‚Ä¢ {}", strategy);
        }
    }

    println!(
        "   
   üìä Performance Comparison:"
    );

    // Simulate performance metrics for different languages
    let performance_metrics = vec![
        ("English", 0.25, 1.2, 95.2),
        ("Spanish", 0.28, 1.1, 92.8),
        ("German", 0.32, 1.4, 91.5),
        ("Japanese", 0.45, 1.8, 88.3),
        ("Chinese", 0.42, 1.6, 89.1),
    ];

    println!(
        "   
   Language        RTF    Memory(GB)   Accuracy(%)"
    );
    println!("   -----------------------------------------------");
    for (language, rtf, memory, accuracy) in performance_metrics {
        println!(
            "   {:12}   {:.2}      {:.1}        {:.1}",
            language, rtf, memory, accuracy
        );
    }

    println!(
        "   
   üí° Optimization Tips:"
    );
    println!("   ‚Ä¢ Use language-specific models when available");
    println!("   ‚Ä¢ Adjust chunk sizes based on language characteristics");
    println!("   ‚Ä¢ Implement language-aware voice activity detection");
    println!("   ‚Ä¢ Cache frequently used language models");
    println!("   ‚Ä¢ Use language-specific text normalization");

    Ok(())
}
