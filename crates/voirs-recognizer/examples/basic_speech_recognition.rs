//! Basic Speech Recognition Example
//!
//! This example demonstrates how to use VoiRS Recognizer for basic speech recognition
//! with automatic audio format detection and high-quality analysis.
//!
//! Usage:
//! ```bash
//! cargo run --example basic_speech_recognition --features="whisper-pure"
//! ```

use std::path::Path;
use tokio;
use voirs_recognizer::audio_formats::ResamplingQuality;
use voirs_recognizer::prelude::*;
use voirs_recognizer::{AudioPreprocessingConfig, AudioPreprocessor, RecognitionError};

#[tokio::main]
async fn main() -> Result<(), RecognitionError> {
    println!("üé§ VoiRS Basic Speech Recognition Example");
    println!("=========================================\n");

    // Step 1: Create some sample audio data (1 second of sine wave at 440Hz)
    println!("üìä Creating sample audio data...");
    let sample_rate = 16000;
    let duration = 1.0; // 1 second
    let frequency = 440.0; // A note

    let mut samples = Vec::new();
    for i in 0..(sample_rate as f32 * duration) as usize {
        let t = i as f32 / sample_rate as f32;
        let sample = 0.1 * (2.0 * std::f32::consts::PI * frequency * t).sin();
        samples.push(sample);
    }

    let audio = AudioBuffer::mono(samples, sample_rate);
    println!(
        "‚úÖ Created audio buffer: {} samples at {}Hz",
        audio.len(),
        audio.sample_rate()
    );

    // Step 2: Analyze audio quality first
    println!("\nüîç Analyzing audio quality...");
    let analyzer_config = AudioAnalysisConfig::default();
    let analyzer = AudioAnalyzerImpl::new(analyzer_config).await?;
    let analysis = analyzer
        .analyze(&audio, Some(&AudioAnalysisConfig::default()))
        .await?;

    // Display quality metrics
    println!("üìà Audio Quality Metrics:");
    for (metric, value) in &analysis.quality_metrics {
        println!("   ‚Ä¢ {}: {:.3}", metric, value);
    }

    // Step 3: Perform voice activity detection
    println!("\nüó£Ô∏è Performing voice activity detection...");
    println!("üìä VAD Results:");
    println!("   ‚Ä¢ Voice activity analysis available through quality metrics");
    if let Some(energy) = analysis.quality_metrics.get("energy") {
        println!("   ‚Ä¢ Energy level: {:.3}", energy);
    }

    // Step 4: Analyze prosody and speaker characteristics
    let prosody = &analysis.prosody;
    {
        println!("\nüéµ Prosody Analysis:");
        println!(
            "   ‚Ä¢ Fundamental frequency (F0): {:.2} Hz",
            prosody.pitch.mean_f0
        );
        println!(
            "   ‚Ä¢ Intonation pattern: {:?}",
            prosody.intonation.pattern_type
        );
        println!(
            "   ‚Ä¢ Speaking rate: {:.2} syllables/sec",
            prosody.rhythm.speaking_rate
        );
    }

    let speaker = &analysis.speaker_characteristics;
    {
        println!("\nüë§ Speaker Characteristics:");
        println!("   ‚Ä¢ Gender: {:?}", speaker.gender);
        println!("   ‚Ä¢ Age range: {:?}", speaker.age_range);
        println!(
            "   ‚Ä¢ Voice characteristics: F0 range {:.1}-{:.1} Hz",
            speaker.voice_characteristics.f0_range.0, speaker.voice_characteristics.f0_range.1
        );
    }

    // Step 5: Demonstrate different audio loading capabilities
    println!("\nüìÅ Audio Format Support:");
    println!("   Supported formats: WAV, FLAC, MP3, OGG, M4A");

    // Create audio load configuration
    let load_config = AudioLoadConfig {
        target_sample_rate: Some(16000),
        force_mono: true,
        normalize: true,
        remove_dc: true,
        max_duration_seconds: None,
    };

    println!("   ‚Ä¢ Audio load configuration created");
    println!(
        "   ‚Ä¢ Target sample rate: {:?}",
        load_config.target_sample_rate
    );
    println!("   ‚Ä¢ Convert to mono: {}", load_config.force_mono);
    println!("   ‚Ä¢ Normalize: {}", load_config.normalize);

    // Step 6: Performance validation
    println!("\n‚ö° Performance Validation:");
    let requirements = PerformanceRequirements::default();
    let validator = PerformanceValidator::with_requirements(requirements);

    println!(
        "   ‚Ä¢ RTF threshold: < {:.2}",
        validator.requirements().max_rtf
    );
    println!(
        "   ‚Ä¢ Memory threshold: < {:.2} GB",
        validator.requirements().max_memory_usage as f64 / (1024.0 * 1024.0 * 1024.0)
    );
    println!(
        "   ‚Ä¢ Startup time threshold: < {:.2}s",
        validator.requirements().max_startup_time_ms as f64 / 1000.0
    );

    // Step 7: Demonstrate preprocessing capabilities
    println!("\nüîß Audio Preprocessing:");
    let preprocessing_config = AudioPreprocessingConfig::default();
    let preprocessor = AudioPreprocessor::new(preprocessing_config.clone())?;

    println!(
        "   ‚Ä¢ Noise suppression: {}",
        preprocessing_config.noise_suppression
    );
    println!("   ‚Ä¢ Automatic gain control: {}", preprocessing_config.agc);
    println!(
        "   ‚Ä¢ Echo cancellation: {}",
        preprocessing_config.echo_cancellation
    );
    println!(
        "   ‚Ä¢ Bandwidth extension: {}",
        preprocessing_config.bandwidth_extension
    );

    // Step 8: Show utility functions
    println!("\nüõ†Ô∏è Utility Functions:");
    let confidence_score = 0.85;
    println!(
        "   ‚Ä¢ Confidence {:.2} = '{}'",
        confidence_score,
        voirs_recognizer::confidence_to_label(confidence_score)
    );

    let asr_config = voirs_recognizer::default_asr_config(LanguageCode::EnUs);
    println!(
        "   ‚Ä¢ Default ASR config for English: language={:?}, word_timestamps={}",
        asr_config.language, asr_config.word_timestamps
    );

    println!("\n‚úÖ Basic speech recognition example completed successfully!");
    println!("üí° Next steps:");
    println!("   ‚Ä¢ Try the real-time processing example");
    println!("   ‚Ä¢ Experiment with different audio formats");
    println!("   ‚Ä¢ Explore multi-language support");
    println!("   ‚Ä¢ Check out custom model integration examples");

    Ok(())
}
