//! Production-ready Whisper example with comprehensive error handling,
//! memory management, and performance monitoring
//!
//! This example demonstrates the full capabilities of the refactored
//! Whisper implementation for production deployments.

use std::time::Instant;
use voirs_recognizer::asr::intelligent_fallback::IntelligentASRFallback;
use voirs_recognizer::asr::whisper::*;
use voirs_recognizer::traits::{ASRFeature, ASRModel};
use voirs_sdk::AudioBuffer;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ðŸŽ¤ Production Whisper ASR Example");
    println!("==================================\n");

    // 1. Initialize with production configuration
    let config = WhisperConfig {
        model_size: "base".to_string(),
        n_audio_state: 512,
        n_audio_head: 8,
        n_audio_layer: 6,
        sample_rate: 16000,
        multilingual: true,
        ..Default::default()
    };

    println!("ðŸ“‹ Initializing Whisper model with configuration:");
    println!("   Model size: {}", config.model_size);
    println!("   Audio state: {}", config.n_audio_state);
    println!("   Sample rate: {}Hz", config.sample_rate);
    println!("   Multilingual: {}\n", config.multilingual);

    // 2. Create model with advanced features
    // Use intelligent fallback system since PureRustWhisper is not available
    let fallback_config = voirs_recognizer::asr::intelligent_fallback::FallbackConfig {
        primary_backend: voirs_recognizer::asr::ASRBackend::Whisper {
            model_size: voirs_recognizer::asr::WhisperModelSize::Base,
            model_path: None,
        },
        fallback_backends: vec![voirs_recognizer::asr::ASRBackend::Whisper {
            model_size: voirs_recognizer::asr::WhisperModelSize::Tiny,
            model_path: None,
        }],
        ..Default::default()
    };
    let model = match IntelligentASRFallback::new(fallback_config).await {
        Ok(model) => model,
        Err(e) => {
            eprintln!("âŒ Failed to initialize model: {e}");
            return Err(e.into());
        }
    };

    println!("âœ… Model initialized successfully");
    let metadata = model.metadata();
    println!("   Model: {}", metadata.name);
    println!("   Architecture: {}\n", metadata.architecture);

    // 3. Create test audio (sine wave for demonstration)
    let audio = create_test_audio(10.0, 16000).await?;
    println!("ðŸ”Š Created test audio: {:.1}s duration\n", audio.duration());

    // 4. Model capabilities overview
    println!("ðŸ“Š Model Capabilities:");
    let metadata = model.metadata();
    println!("   Supported Languages: {:?}", metadata.supported_languages);
    println!("   Architecture: {}", metadata.architecture);
    println!("   Model Size: {:.1}MB", metadata.model_size_mb);
    println!("   Features: {:?}\n", metadata.supported_features);

    // 5. Model capabilities check
    println!("ðŸ” Feature Support:");
    println!(
        "   Word Timestamps: {}",
        model.supports_feature(ASRFeature::WordTimestamps)
    );
    println!(
        "   Language Detection: {}",
        model.supports_feature(ASRFeature::LanguageDetection)
    );
    println!(
        "   Noise Robustness: {}\n",
        model.supports_feature(ASRFeature::NoiseRobustness)
    );

    // 6. Transcription with error handling
    println!("ðŸŽ¯ Performing transcription...");
    let transcription_start = Instant::now();

    match model.transcribe(&audio, None).await {
        Ok(transcript) => {
            let duration = transcription_start.elapsed();
            let rtf = duration.as_secs_f32() / audio.duration();

            println!("âœ… Transcription successful!");
            println!("   Text: \"{}\"", transcript.transcript.text.trim());
            println!(
                "   Confidence: {:.1}%",
                transcript.transcript.confidence * 100.0
            );
            println!("   Processing time: {:.2}s", duration.as_secs_f32());
            println!("   Real-time factor: {rtf:.3}");
        }
        Err(e) => {
            println!("âŒ Transcription failed: {e}");

            // Note: Simple fallback mechanism is built into IntelligentASRFallback
            println!("ðŸ”„ Fallback mechanism will attempt alternative models automatically");
        }
    }
    println!();

    // 7. Note about streaming capabilities
    println!("ðŸ“¡ Streaming Capabilities:");
    println!("   IntelligentASRFallback supports streaming through primary model");
    println!("   Streaming is handled by the underlying Whisper implementation");
    println!("   Real-time processing depends on model selection\n");

    // 8. Final system state
    println!("ðŸ“ˆ Final System State:");
    let final_stats = model.get_stats().await;
    println!("   Total requests: {}", final_stats.total_requests);
    println!(
        "   Fallbacks triggered: {}",
        final_stats.fallbacks_triggered
    );
    println!(
        "   Success rate: {:.1}%",
        final_stats.fallback_success_rate * 100.0
    );
    println!("   Average attempts: {:.1}", final_stats.average_attempts);
    println!();

    // 9. Cleanup
    println!("ðŸ§¹ Performing cleanup...");
    println!("   IntelligentASRFallback handles cleanup automatically");

    println!("âœ… Example completed successfully!");

    Ok(())
}

/// Create test audio buffer with sine wave
async fn create_test_audio(
    duration: f32,
    sample_rate: u32,
) -> Result<AudioBuffer, Box<dyn std::error::Error>> {
    let samples_count = (duration * sample_rate as f32) as usize;
    let samples: Vec<f32> = (0..samples_count)
        .map(|i| {
            // Generate a sine wave at 440Hz (A4 note)
            let t = i as f32 / sample_rate as f32;
            (t * 440.0 * 2.0 * std::f32::consts::PI).sin() * 0.1
        })
        .collect();

    Ok(AudioBuffer::new(samples, sample_rate, 1))
}
